---
layout: default
title: Home
description: "Yana Veitsman - PhD student at Universität Göttingen working on cognitively plausible strategies for multilingual NLP, interpretability, and efficient modeling."
permalink: /
---

<div class="about-wrapper">

  <!-- Profile photo -->
  <img src="{{ '/assets/images/profile.png' | relative_url }}"
       alt="Profile picture of Yana Veitsman"
       class="profile-pic">

  <!-- Bio text -->
  <div class="about-text">
    <p>
      Hi! I’m currently a <strong>first-year PhD student</strong> at <strong>Universität Göttingen</strong> with 
      <a href="https://beinborn.eu" target="_blank" rel="noopener">Prof.&nbsp;Dr.&nbsp;Lisa&nbsp;Beinborn</a>, 
      working on <em>cognitively plausible strategies for sample-efficient modeling in multilingual NLP</em>.
    </p>
    
    <p>
      I completed my <strong>Master’s degree at Saarland University</strong>, where I worked as a 
      <strong>student research assistant</strong> under
      <a href="https://www.mhahn.info" target="_blank" rel="noopener">Prof.&nbsp;Dr.&nbsp;Michael&nbsp;Hahn</a>
      and <a href="https://www.uni-saarland.de/lehrstuhl/demberg/members/verademberg.html" target="_blank" rel="noopener">Prof.&nbsp;Dr.&nbsp;Vera&nbsp;Demberg</a>.
    </p>
    
    <p>
      During my Master’s, I worked on several projects covering different aspects of large language models, from the expressivity of transformer and state-space models to mechanistic interpretability in in-context learning and persistent theoretical limitations of the transformer architecture.
    </p>
    
    <p>
      I also completed my Master’s thesis with 
      <a href="https://yihongl1u.github.io" target="_blank" rel="noopener">Yihong&nbsp;Liu</a> at the 
      <a href="https://cisnlp.github.io" target="_blank" rel="noopener">Schütze&nbsp;Lab</a> at LMU Munich, investigating 
      <em>why better cross-lingual alignment does not necessarily lead to better cross-lingual transfer</em>.
    </p>

    <p>
      My research interests continue to revolve around <strong>multilingual NLP</strong>, 
      <strong>interpretability</strong>, and <strong>efficiency</strong>.
      I hope to help turn the Left-Behinds and the Scraping-Bys<sup id="fnref-acl"><a href="#fn-acl" class="footnote-ref">[1]</a></sup>
      at the very least into Hopeful and Rising Stars of the field.
    </p>

    <p>
      Outside of work, I make other people laugh, lift heavy things, and experiment with the sourness level of my signature cocktails. I have recently held my first solo <a href="https://drive.google.com/file/d/1y3fige5NksN07vhjLEMqKVjOF0xMCCcm/view?usp=sharing" target="_blank">stand-up comedy show</a>. So, either see me at the show or come by to discuss what rep range is the best for muscle hypertrophy over a Moscow Mule! Feel free to hit me up.
     </p>
  </div>

</div>

<!-- Footnotes ----------------------------------------------------------- -->
<ol class="footnotes">
  <li id="fn-acl">
    1. Joshi et&nbsp;al.&nbsp;(2020).
    “<em>The State and Fate of Linguistic Diversity in the NLP World</em>.”
    <a href="https://aclanthology.org/2020.acl-main.560/" target="_blank" rel="noopener">
      ACL&nbsp;2020.
    </a>
  </li>
</ol>
